### Cost Function and Learning Algorithm

Based on the aforementioned truth, we can define a cost function $\psi: \mathbb{R}^m \rightarrow \mathbb{R}$ such that $\psi(\varpi_1^L, \varpi_2^L, \dots, \varpi_m^L)$ where \(\varpi\) are the weights of layer $L$ of our artificial neural network. We will also define $Y = \varphi(W^L \cdot A^{L-1[b]})$ as the output of the layer and $\hat{Y}$ as the expected output of the layer. The result of the function $\psi$ is precisely the error between the layer output and the expected output. An example is given below:

\[
\psi_{\text{MSE}}(\varpi_1^L, \dots, \varpi_m^L) = \frac{1}{m}\sum_{i=1}^{m}(y_i(\varpi_i^L) - \hat{y}_i)^2
\]

In $\psi_{MSE}$, we are using each element of $Y_{m \times 1}$ as $y_i$. Recapping the structure of $Y$ to define the situation of $y_i$:

\[
Y = \begin{bmatrix} y_1 \\ \vdots \\ y_m\end{bmatrix} = \begin{bmatrix} a_1^L \\ \vdots \\ a_m^L\end{bmatrix} = \begin{bmatrix} \varphi(\varpi_1^L \cdot A^{L-1[b]}) \\ \vdots \\ \varphi(\varpi_m^L \cdot A^{L-1[b]})\end{bmatrix}
\]

Thus, we can define $y_i$ as:

\[
y_i = \varphi(\varpi_i^L \cdot A^{L-1[b]}), \quad \varpi_i^L = \begin{bmatrix} w_{0[i]}^L, w_{1[i]}^L, \dots, w_{k_{L-1[b]}[i]}^L \end{bmatrix}, \quad A^{L-1[b]} = \begin{bmatrix} a_0^L \\ a_1^L \\ \vdots \\ a_{k_{L-1[b]}}^L\end{bmatrix}
\]

To elucidate the definition of the output \(y_i\), we have the representation below:

<img src="/output_i_definition.svg" alt="Output y_i definition"/>

Notice that in the vector \(A^{L-1[b]}\), we have the dimension \(k\) referring to layer \(L-1\) with the additional bias \(a_0^{L-1}\), denoted by \([b]\). Thus, the dimension is denoted by \(k_{L-1}[b]\). Similarly, the dimension of \(\varpi_i^L\) where we know that \(\forall a_i^{L-1} \exists w_i^{L}\) such that \(i = 0, \dots, k_{L-1}[b]\).

Therefore, our primary goal is to understand how the weights \(\varpi_i^L\) influence the result of the cost function \(\psi(\varpi_1^L, \dots, \varpi_m^L)\). So:

\[
\frac{\partial}{\partial \varpi_i^L} \psi_{\text{MSE}}(\varpi_1^L, \dots, \varpi_m^L)
\]

We know how \(\psi_{\text{MSE}}\) is defined, and we also know that:

\[
    y_i = a_i^L = \varphi(z_i^L) =\varphi(\varpi_i^L \cdot A^{L-1[b]})
\]

In the cost function, to facilitate our deductions, we can define \((y_i - \hat{y_i})^2 = E_i\) where \(E_i\) represents the squared error of each output of our ANN. Then we have:

\[
\frac{\partial}{\partial \varpi_i^L} \psi_{\text{MSE}}(\varpi_1^L, \dots, \varpi_m^L) = \frac{1}{m}\frac{\partial}{\partial \varpi_i^L} \sum_{i=1}^{m} E_i
\]

Based on this, we can apply the chain rule until we have a differentiable function with respect to \(\varpi_i^L\):

\[
\frac{\partial}{\partial \varpi_i^L} \sum_{i=1}^{m} E_i = \frac{\partial E_i}{\partial a_i^L}\frac{\partial a_i^L}{\partial z_i^L}\frac{\partial z_i^L}{\partial \varpi_i^L}
\]

Notice that there is no longer a summation applied to the partial derivatives. This is because we are deriving with respect to \(\varpi_i^L\), so all terms that do not depend on \(\varpi_i^L\) result in zero.

Therefore, solving the partial derivative for \(E_i\):

\[
\frac{\partial E_i}{\partial a_i^L} = \frac{\partial}{\partial a_i^L}(y_i - \hat{y_i})^2 = 2(y_i-\hat{y_i})
\]

The above resolution is true because \(y_i = a_i^L\). Now solving the partial derivative for \(a_i^L\):

\[
\frac{\partial a_i^L}{\partial z_i^L} = \frac{\partial \varphi(z_i^L)}{\partial z_i^L} = \dot{\varphi}(z_i^L)
\]

We use the Newtonian notation to represent the derivative of \(\varphi\). The activation function, as mentioned earlier, can be defined in numerous ways, so we denote it in this format. Finally, solving for \(z_i^L\):

\[
\frac{\partial z_i^L}{\partial \varpi_i^L} = \frac{\partial}{\partial \varpi_i^L} (\varpi_i^L \cdot A^{L-1[b]}) = A^{L-1[b]}
\]

This way, we know how the cost function behaves with the variation of the weights \(\varpi_i^L\):

\[
\frac{\partial}{\partial \varpi_i^L} \psi_{\text{MSE}}(\varpi_1^L, \dots, \varpi_m^L) = \frac{1}{m}\left[2(y_i - \hat{y_i}) \dot{\varphi}(z_i^L) \cdot A^{L-1[b]} \right]
\]

Simplifying, we can define \(\delta_i^L = 2(y_i-\hat{y_i})\dot{\varphi}(z_i^L)\), then we have our formalized definition:

\[
\frac{\partial}{\partial \varpi_i^L} \psi_{\text{MSE}}(\varpi_1^L, \dots, \varpi_m^L) = \frac{1}{m}\delta_i^L \cdot A^{L-1[b]}
\]

Based on what we saw in the Theoretical Learning Algorithm topic, where we proved that \(f(x-\alpha \nabla f(x)) \leq f(x)\) where \(f: \mathbb{R} \rightarrow \mathbb{R}\), we can apply the same idea to the cost function. Our goal is to achieve the smallest possible value of the cost function \(\psi_{\text{MSE}}\) by modifying the weights \(\varpi\).

Recalling the structure of the algorithm that satisfies \(f(x - \alpha \nabla f(x)) \leq f(x)\) where \(x = \begin{bmatrix} x_0 & \dots & x_n \end{bmatrix}\), and \(f: \mathbb{R}^n \rightarrow \mathbb{R}\):

\[
\begin{bmatrix} x_{0[r+1]} \\ \vdots \\ x_{n[r+1]}\end{bmatrix} := \begin{bmatrix} x_{0[r]} \\ \vdots \\ x_{n[r]}\end{bmatrix} - \alpha \begin{bmatrix} \frac{\partial f(x)}{\partial x_{0[r]}} \\ \vdots \\ \frac{\partial f(x)}{\partial x_{n[r]}}  \end{bmatrix}
\]

We add the term \(r\) to represent the states of the elements of \(x\), where \(r+1\) represents a state after adjustment by the algorithm. Therefore, for the adjustment of any \(x_i\), we have:

\[
x_{i[r+1]} := x_{i} - \alpha \frac{\partial f(x)}{\partial x_i}
\]

Now, we can apply the same format to the cost function \(\psi_{\text{MSE}}(\varpi_1^L, \dots, \varpi_m^L)\):

\[
\varpi_{i[r+1]}^L := \varpi_{i[r]}^L - \alpha \frac{\partial }{\partial \varpi_{i[r]}^L} \psi_{\text{MSE}}(\varpi_{1[r]}^L, \dots, \varpi_{m[r]}^L)
\]

We already know the derivative of the cost function with respect to \(\varpi_i^L\), so:

\[
\varpi_{i[r+1]}^L := \varpi_{i[r]}^L -  \frac{\alpha}{m}\delta_{i[r]}^L \cdot A^{L-1[b]}
\]

Therefore, knowing that \(\varpi_i^L\) is a vector containing all the weights of the neuron \(a_i^L\):

\[
\begin{bmatrix} w_{0[i][r+1]}^L \\ \vdots \\ w_{k_{L-1[b]}[i][r+1]}^L \end{bmatrix} = \begin{bmatrix} w_{0[i][r]}^L \\ \vdots \\ w_{k_{L-1[b]}[i][r]}^L \end{bmatrix} - \frac{\alpha}{m}\delta_{i[r]}^L \begin{bmatrix} a_{0}^{L-1} \\ \vdots \\ a_{k_{L-1[b]}}^{L-1}\end{bmatrix}
\]

#### Weight Update \(w^L\)

So, to update a weight \(w_{h[i]}^L\) where \(h \in \{ 0, 1, \dots, k_{L-1[b]}\}\) properly of a neuron \(i\) in layer \(L\) where \(i \in \{ 1, 2, \dots, m \}\), we have:

\[
w_{h[i][r+1]}^L := w_{h[i][r]}^L - \frac{\alpha}{m}\delta_{i[r]}^L a_h^{L-1} 
\]

Where \(\alpha\) can be named the _learning rate_ since \((\alpha \rightarrow 0)\), \(m\) being the number of output neurons, \(a_h^{L-1}\) being the output of neuron \(h\) from layer \(L-1\), and \(\delta_i^L = 2(y_i - \hat{y_i})\dot{\varphi}(z_i^L)\) where \(y_i - \hat{y_i}\) represents the difference between the output of neuron \(i\) from layer \(L\) and its expected output, and \(\dot{\varphi}(z_i^L)\) is the derivative of the activation function with respect to the result of the transfer function of neuron \(i\) from layer \(L\).